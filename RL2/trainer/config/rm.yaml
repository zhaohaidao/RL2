data:
  path: null
  max_length: null
  batch_size: 128

critic:
  model_name: null
  tokenizer_name: ${critic.model_name}
  gradient_checkpointing: true
  ddp_size: 1
  tp_size: 1
  sp_size: 1
  optimizer_dir: null
  max_length_per_device: null
  lr: 1e-5
  weight_decay: 1e-2
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  offload_optimizer: true
  save_dir: ckpts/${trainer.experiment_name}
  save_freq: null
  save_optimizer: true

  lora:
    rank: 0
    alpha: 16
    target_modules: all-linear
    dropout: 0

trainer:
  project: null
  experiment_name: null
  n_epochs: 1
  disable_wandb: false